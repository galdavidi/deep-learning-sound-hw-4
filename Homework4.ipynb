{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwqtbpw7WYDw"
      },
      "source": [
        "#### Student Name:\n",
        "#### Student ID:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eK-fy4cmWYD1"
      },
      "source": [
        "# Overview\n",
        "### Due Jan 25th\n",
        "\n",
        "### GAN, chroma (MIDI) and pix2pix\n",
        "\n",
        "Instructions:\n",
        "\n",
        "* This notebook is an interactive assignment; please read and follow the instructions in each cell.\n",
        "\n",
        "* Cells that require your input (in the form of code or written response) will have 'Question #' above.\n",
        "\n",
        "* After completing the assignment, please submit this notebook and printout as a PDF.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wkG3YX39I6u1"
      },
      "outputs": [],
      "source": [
        "# If you're collaboraing with a classmate, please fill in the following:\n",
        "\n",
        "collaboration = {\n",
        "    \"PLACE YOUR STUDENT ID HERE\" : \"PLACE YOUR COLLABORATOR'S STUDENT ID HERE\"\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mUtlgRDWYD3"
      },
      "source": [
        "In this notebook we explore a style transfer application that tries to change the musical texture of a piece while maintaining the harmonic structure. In order to do so we train a pix2pix type of model that learns the relations between chroma and the musical texture (distribution of notes). For this purpose we extract chroma from MIDI data and learn a generator that complements the notes from a given texture. You can think about this as something similar to pix2pix that learns completion of image textures from a sketch. In the image GAN the contours for training are generated using an edge detection on a complete image. You can read more about the history of Midi formats at https://cecm.indiana.edu/361/midi.html#:~:text=MIDI%20is%20an%20acronym%20that,each%20other%2C%20using%20MIDI%20messages."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXqiXvjmGkVv"
      },
      "source": [
        "# 1. Imports and Loading Data\n",
        "Before running, please download the files from https://drive.google.com/drive/folders/1B3WpC9hRH4W6yzh7gahFAZodw1lP4aaM?usp=share_link make sure to upload the following to your python directory\n",
        "- reverse_pianoroll.py\n",
        "- convert.py\n",
        "- Classical_Music_Midi.zip and unzip it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o8ztrskPi2TJ"
      },
      "outputs": [],
      "source": [
        "# !unzip content/Classical_Music_Midi.zip -d content/Classical_Music_Midi/\n",
        "#!pip install down\n",
        "#!gdown --folder https://drive.google.com/drive/folders/1B3WpC9hRH4W6yzh7gahFAZodw1lP4aaM --output ./content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "dAiCT0DTi2s4"
      },
      "outputs": [],
      "source": [
        "# !brew install -y fluidsynth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "zauwJ6Npi34v"
      },
      "outputs": [],
      "source": [
        "# !pip install --upgrade pyfluidsynth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "eAwx7RQpi5yk"
      },
      "outputs": [],
      "source": [
        "# !pip install pretty_midi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zR2xjd5_8g2N"
      },
      "outputs": [],
      "source": [
        "import pretty_midi\n",
        "from  content import reverse_pianoroll\n",
        "from content import convert\n",
        "import librosa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LNiQvohD8g25"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import sys\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "SWV1ONBqEj1t"
      },
      "outputs": [],
      "source": [
        "#all necessary imports: use pip install [library name] to add to environment\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "#import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "import os\n",
        "from os import listdir\n",
        "import glob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "t0MVvlIeEj1v"
      },
      "outputs": [],
      "source": [
        "#add songs to data\n",
        "def get_songs(path):\n",
        "    files = glob.glob('{}/*.mid*'.format(path))\n",
        "    songs = {}\n",
        "    for f in files:\n",
        "        try:\n",
        "            data = pretty_midi.PrettyMIDI(f)\n",
        "            song = data.get_piano_roll(fs=16)\n",
        "            song = convert.forward(song)\n",
        "            # song = np.transpose(song) #if your code matrices aren't working, try uncommenting this. the convert.py file might not be updated\n",
        "            songs[f] = {\n",
        "                'original_midi': data,\n",
        "                'song': song\n",
        "            }\n",
        "        except Exception as e:\n",
        "            raise e\n",
        "    return songs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Xmg6hl8KjBJc"
      },
      "outputs": [],
      "source": [
        "from IPython import display\n",
        "import fluidsynth\n",
        "\n",
        "_SAMPLING_RATE = 16000\n",
        "def display_audio(pm: pretty_midi.PrettyMIDI, seconds=30):\n",
        "  waveform = pm.fluidsynth(fs=_SAMPLING_RATE)\n",
        "  # Take a sample of the generated waveform to mitigate kernel resets\n",
        "  waveform_short = waveform[:seconds*_SAMPLING_RATE]\n",
        "  return display.Audio(waveform_short, rate=_SAMPLING_RATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "8iihxLXwEj1w",
        "outputId": "1ece621f-2808-40e3-dade-378de66ba1c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "21 songs processed\n",
            "21 chromas processed\n"
          ]
        }
      ],
      "source": [
        "#custom function to extract chroma features from song\n",
        "def add_chromas(songs):\n",
        "    \"\"\"\n",
        "    the add_chromas function takes in a dictionary of songs and adds a chroma feature to each song in the dictionary.\n",
        "    for each song in the songs (which is the piano roll of the song), extract the chroma features by finding the notes that are \n",
        "    played at each time step. \n",
        "    by checking if the value of the note is greater than 0. if so we find the note using mod 12 and increment the corresponding \n",
        "    index in the chroma vector.\n",
        "    \"\"\"\n",
        "    chromas = []\n",
        "    for song in songs:\n",
        "        chroma = np.zeros(shape=(np.shape(songs[song]['song'])[0], 12))\n",
        "        for i in np.arange(np.shape(songs[song]['song'])[0]): # for each time step\n",
        "            for j in np.arange(78): # the shape of songs[song]['song'][i] is 156 (78*2)   \n",
        "                if songs[song]['song'][i][j] > 0:\n",
        "                    chroma[i][np.mod(j,12)] += 1 # there are 12 notes in an octave so we can just mod by 12 to get the correct chord index\n",
        "        songs[song]['chroma'] = chroma\n",
        "\n",
        "    return songs\n",
        "\n",
        "songs = get_songs('./content/Classical_Music_Midi/mozart')\n",
        "songs = add_chromas(songs)\n",
        "print (\"{} songs processed\".format(len(['song' in songs[f] for f in songs])))\n",
        "print (\"{} chromas processed\".format(len(['chroma' in songs[f] for f in songs])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzToDZo1WYD_"
      },
      "source": [
        "#### Exploring the song and chroma representations\n",
        "\n",
        "Looking at a random song segment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "XjqIzFx7WYD_",
        "outputId": "686477ca-27d3-4432-d46a-965b6acfc66e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((3809, 156), (3809, 12))"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cur_song = list(songs.keys())[0]\n",
        "song = songs[cur_song]['song']\n",
        "chroma = songs[cur_song]['chroma']\n",
        "np.shape(song), np.shape(chroma)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "stw04DAGWYEA",
        "outputId": "a7e3ffef-4d75-41fa-9cd9-bf0039ae55cc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x16e34d5b0>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 2000x1000 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize = (20,10))\n",
        "plt.imshow(100*song[:100,:].T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "7QJ3I7UWWYEB",
        "outputId": "f071f113-edaa-4c7a-d163-2ce87321b96f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x143b23650>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABj0AAADlCAYAAAAIujXoAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAGZRJREFUeJzt3QuMVPW9B/DfwOJC6e4W8cWGRbnojQ8QfKAoxmAkEq8aSK3VBBuKTbUVH0CrlaZgfK6aVogvUNOqTUWxybVYc8UYWrRW3qjRtAWppm4kgCY6oxhXYOfmnBv2sgVR3JmdnbOfT3Iye86c5f9nd+c3j+/5//+5YrFYDAAAAAAAgCrXq9IdAAAAAAAAKAWhBwAAAAAAkAlCDwAAAAAAIBOEHgAAAAAAQCYIPQAAAAAAgEwQegAAAAAAAJkg9AAAAAAAADKhJrqZtra22LRpU9TV1UUul6t0dwAAAAAAgAoqFovx8ccfR2NjY/Tq1au6Qo8k8Ghqaqp0NwAAAAAAgG6kpaUlBg8eXF2hRzLCI3FG/FfURJ9KdwcAoGzevmN09ESvf/s3nfr+kf99Wcn6At3Vf9ywOnqiztTFnvozg/3htUfX87qFauA5lGqwI7bHy/E/7flBVYUeu6a0SgKPmpzQAwDIrl59+0ZPVF/XuWXleurPjZ6lp74X6szju6f+zGB/9NTn0M6+9uiMnvozp7p4DqUqFP/v5qssiWEhcwAAAAAAIBPKFnrcf//9ccQRR0Tfvn3j1FNPjVWrVpWrKQAAAAAAgPKEHosWLYqZM2fGjTfeGOvWrYuRI0fGhAkTYuvWreVoDgAAAAAAoDyhx9133x0//OEPY+rUqXHsscfGggUL4hvf+Eb85jeVWzgKAAAAAADItpKHHp9//nmsXbs2xo8f//+N9OqV7i9fvnyP81tbW6NQKHTYAAAAAAAAKh56fPDBB7Fz58449NBDOxxP9jdv3rzH+c3NzdHQ0NC+NTU1lbpLAAAAAABAD1C2hcy/qlmzZkU+n2/fWlpaKt0lAAAAAACgCtWU+h886KCDonfv3rFly5YOx5P9ww47bI/za2tr0w0AAAAAAKBbjfQ44IAD4qSTToqlS5e2H2tra0v3TzvttFI3BwAAAAAAUJ6RHomZM2fGlClT4uSTT45TTjkl5s2bF9u2bYupU6eWozkAAAAAAIDyhB4XX3xxvP/++zFnzpx08fJRo0bFkiVL9ljcHAAAAAAAoFuHHomrrroq3QAAAAAAALpCrlgsFqMbKRQK0dDQEONiYtTk+lS6OwAAAAAAQAXtKG6PZbE48vl81NfXd+1C5gAAAAAAAJUg9AAAAAAAADJB6AEAAAAAAGSC0AMAAAAAAMgEoQcAAAAAAJAJQg8AAAAAACAThB4AAAAAAEAmCD0AAAAAAIBMEHoAAAAAAACZIPQAAAAAAAAyQegBAAAAAABkgtADAAAAAADIBKEHAAAAAACQCUIPAAAAAAAgE2oq3QHojOc3vVbpLvQ4ExpHVboLVJGe+hj1OKkuG+eOqVjbR85YUbG2e+r/G6pFJR+jneHxDV/Oc3DX/8yq9f8NXaWaH2Od6Xu19rua69rGTvy/2z77LOKGxV/pXCM9AAAAAACATBB6AAAAAAAAmSD0AAAAAAAAMkHoAQAAAAAAZELJQ4/m5uYYPXp01NXVxSGHHBKTJk2K9evXl7oZAAAAAACA8oYeL774YkybNi1WrFgRL7zwQmzfvj3OOeec2LZtW6mbAgAAAAAAaFcTJbZkyZIO+48++mg64mPt2rVx5plnlro5AAAAAACA8oQe/y6fz6e3Bx544F7vb21tTbddCoVCubsEAAAAAABkUFkXMm9ra4vp06fH2LFjY/jw4V+4BkhDQ0P71tTUVM4uAQAAAAAAGVXW0CNZ2+PNN9+MJ5988gvPmTVrVjoaZNfW0tJSzi4BAAAAAAAZVbbpra666qp49tln46WXXorBgwd/4Xm1tbXpBgAAAAAA0K1Cj2KxGFdffXU8/fTTsWzZshg6dGipmwAAAAAAACh/6JFMabVw4cJYvHhx1NXVxebNm9PjyXod/fr1K3VzAAAAAAAA5VnTY/78+enaHOPGjYtBgwa1b4sWLSp1UwAAAAAAAOWd3goAAAAAAKCr5YrdLKUoFArpVFjjYmLU5PpUujsAAGWzce6YTn3/Py9eEJUybNGPKtY29ARHzlhR6S7QhfXc75tq+Fv1ugOyy/MQ1WBHcXssi8XpLFP19fVdO70VAAAAAABAJQg9AAAAAACATBB6AAAAAAAAmSD0AAAAAAAAMkHoAQAAAAAAZILQAwAAAAAAyAShBwAAAAAAkAlCDwAAAAAAIBOEHgAAAAAAQCYIPQAAAAAAgEwQegAAAAAAAJkg9AAAAAAAADJB6AEAAAAAAGSC0AMAAAAAAMiEXLFYLEY3UigUoqGhIcbFxKjJ9al0dwAAoMfbOHdMxdo+csaKirUNPeHx6TEGdDdedwB7s6O4PZbF4sjn81FfXx/7YqQHAAAAAACQCUIPAAAAAAAgE4QeAAAAAABAJgg9AAAAAACATCh76HHHHXdELpeL6dOnl7spAAAAAACgBytr6LF69ep48MEH4/jjjy9nMwAAAAAAAOULPT755JOYPHlyPPzwwzFgwIByNQMAAAAAAFDe0GPatGlx3nnnxfjx4/d5XmtraxQKhQ4bAAAAAADA/qqJMnjyySdj3bp16fRWX6a5uTluuummcnQDAAAAAADoQUo+0qOlpSWuvfbaePzxx6Nv375fev6sWbMin8+3b8n3AwAAAAAAVHykx9q1a2Pr1q1x4oknth/buXNnvPTSS3Hfffel01n17t27/b7a2tp0AwAAAAAA6Fahx9lnnx1vvPFGh2NTp06No48+On72s591CDwAAAAAAAC6behRV1cXw4cP73Csf//+MXDgwD2OAwAAAAAAdNs1PQAAAAAAADIx0mNvli1b1hXNAAAAAAAAPViXhB50f89vei2q0YTGUZXuQo9TrX8rCX8vdJVqfpxUq2p9fHf2b2XYoh+VrC9k2z8vXtCp7x+2aExU4+Okmh8jR85YUeku0EP+VjbOHVOVfa/WfldaT62pVNtrj8q9Ru6pr8+rua5Vq84+j/md7ZvprQAAAAAAgEwQegAAAAAAAJkg9AAAAAAAADJB6AEAAAAAAGSC0AMAAAAAAMgEoQcAAAAAAJAJQg8AAAAAACAThB4AAAAAAEAmCD0AAAAAAIBMEHoAAAAAAACZIPQAAAAAAAAyQegBAAAAAABkgtADAAAAAADIBKEHAAAAAACQCblisViMbqRQKERDQ0OMi4lRk+tT6e4AAAAAAAAVtKO4PZbF4sjn81FfX7/Pc430AAAAAAAAMkHoAQAAAAAAZILQAwAAAAAAyAShBwAAAAAAkAllCT3ee++9uPTSS2PgwIHRr1+/GDFiRKxZs6YcTQEAAAAAAKRqosQ+/PDDGDt2bJx11lnx3HPPxcEHHxxvvfVWDBgwoNRNAQAAAAAAlC/0uPPOO6OpqSkeeeSR9mNDhw4tdTMAAAAAAADlnd7qmWeeiZNPPjkuuuiiOOSQQ+KEE06Ihx9++AvPb21tjUKh0GEDAAAAAACoeOjx9ttvx/z58+Ooo46K559/Pn784x/HNddcE4899thez29ubo6Ghob2LRklAgAAAAAAsL9yxWKxGCV0wAEHpCM9XnnllfZjSeixevXqWL58+V5HeiTbLslIjyT4GBcToybXp5RdAwAAAAAAqsyO4vZYFosjn89HfX191470GDRoUBx77LEdjh1zzDHx7rvv7vX82tratJO7bwAAAAAAAPur5KHH2LFjY/369R2ObdiwIQ4//PBSNwUAAAAAAFC+0GPGjBmxYsWKuP3222Pjxo2xcOHCeOihh2LatGmlbgoAAAAAAKB8ocfo0aPj6aefjieeeCKGDx8et9xyS8ybNy8mT55c6qYAAAAAAADa1UQZnH/++ekGAAAAAABQ1aEHAADQ0ca5YyrW9pEzVkRP5GcO2X2MeoxB934O7amPUa89IKPTWwEAAAAAAFSC0AMAAAAAAMgEoQcAAAAAAJAJQg8AAAAAACAThB4AAAAAAEAmCD0AAAAAAIBMEHoAAAAAAACZIPQAAAAAAAAyQegBAAAAAABkgtADAAAAAADIBKEHAAAAAACQCUIPAAAAAAAgE4QeAAAAAABAJgg9AAAAAACATBB6AAAAAAAAmZArFovF6EYKhUI0NDTEuJgYNbk+le4OAAAAAABQQTuK22NZLI58Ph/19fX7PNdIDwAAAAAAIBOEHgAAAAAAQCYIPQAAAAAAgEwoeeixc+fOmD17dgwdOjT69esXw4YNi1tuuSW62dIhAAAAAABAxtSU+h+88847Y/78+fHYY4/FcccdF2vWrImpU6emi5Nfc801pW4OAAAAAACgPKHHK6+8EhMnTozzzjsv3T/iiCPiiSeeiFWrVpW6KQAAAAAAgPJNb3X66afH0qVLY8OGDen+66+/Hi+//HKce+65ez2/tbU1CoVChw0AAAAAAKDiIz1uuOGGNLg4+uijo3fv3ukaH7fddltMnjx5r+c3NzfHTTfdVOpuAAAAAAAAPUzJR3o89dRT8fjjj8fChQtj3bp16doev/zlL9PbvZk1a1bk8/n2raWlpdRdAgAAAAAAeoCSj/S47rrr0tEel1xySbo/YsSI+Ne//pWO6JgyZcoe59fW1qYbAAAAAABAtxrp8emnn0avXh3/2WSaq7a2tlI3BQAAAAAAUL6RHhdccEG6hseQIUPiuOOOi1dffTXuvvvuuOyyy0rdFAAAAAAAQPlCj3vvvTdmz54dV155ZWzdujUaGxvjiiuuiDlz5pS6KQAAAAAAgHa5YrFYjG6kUChEQ0NDjIuJUZPrU+nuAAAAAAAAFbSjuD2WxeLI5/NRX1/ftSM9AAAgqzbOHfO1v/fIGStK2he69++7syr59+LvHKB76KnPQ3w9nr+hjAuZAwAAAAAAVILQAwAAAAAAyAShBwAAAAAAkAlCDwAAAAAAIBOEHgAAAAAAQCYIPQAAAAAAgEwQegAAAAAAAJkg9AAAAAAAADJB6AEAAAAAAGSC0AMAAAAAAMgEoQcAAAAAAJAJQg8AAAAAACAThB4AAAAAAEAmCD0AAAAAAIBMEHoAAAAAAACZkCsWi8XoRgqFQjQ0NMSHG/4j6utkMl1lQuOoSncByu75Ta9Vugs9jtpCV9k4d8zX/t4jZ6woaV/o3r/vzvL3QjX8nf/z4gWdanvYoh997e/1GKEn6OzzkMdJz+J1Kj3h85JKvvfvTN8r2e+e+lzyfCd+X4WP22LAf74d+Xw+6uvr93muVAEAAAAAAMgEoQcAAAAAAJAJQg8AAAAAAKBnhh4vvfRSXHDBBdHY2Bi5XC7+8Ic/dLg/WSJkzpw5MWjQoOjXr1+MHz8+3nrrrVL2GQAAAAAAoPOhx7Zt22LkyJFx//337/X+u+66K+65555YsGBBrFy5Mvr37x8TJkyIzz77bH+bAgAAAAAA+MpqYj+de+656bY3ySiPefPmxS9+8YuYOHFieuy3v/1tHHrooemIkEsuuWR/mwMAAAAAAOj6NT3eeeed2Lx5czql1S4NDQ1x6qmnxvLly/f6Pa2trVEoFDpsAAAAAAAAFQ09ksAjkYzs2F2yv+u+f9fc3JwGI7u2pqamUnYJAAAAAADoIUoaenwds2bNinw+3761tLRUuksAAAAAAEBPDz0OO+yw9HbLli0djif7u+77d7W1tVFfX99hAwAAAAAAqGjoMXTo0DTcWLp0afuxZI2OlStXxmmnnVbKpgAAAAAAADqoif30ySefxMaNGzssXv7aa6/FgQceGEOGDInp06fHrbfeGkcddVQagsyePTsaGxtj0qRJ+9sUAAAAAABA+UKPNWvWxFlnndW+P3PmzPR2ypQp8eijj8b1118f27Zti8svvzw++uijOOOMM2LJkiXRt2/f/W0KAAAAAACgfKHHuHHjolgsfuH9uVwubr755nQDAAAAAADoKrnivhKMCkjWAGloaIhxMTFqcn0q3R0AAAAAAKCCdhS3x7JYHPl8Purr67tuIXMAAAAAAIBKEXoAAAAAAACZIPQAAAAAAAAyQegBAAAAAABkgtADAAAAAADIBKEHAAAAAACQCUIPAAAAAAAgE4QeAAAAAABAJgg9AAAAAACATBB6AAAAAAAAmSD0AAAAAAAAMkHoAQAAAAAAZILQAwAAAAAAyAShBwAAAAAAkAk10c0Ui8X0dkdsj/i/LwEAAAAAgB5qR5IX7JYfVFXo8fHHH6e3L8f/VLorAAAAAABAN8oPGhoa9nlOrvhVopEu1NbWFps2bYq6urrI5XJ73F8oFKKpqSlaWlqivr6+In0EKCV1DcgadQ3IGnUNyBp1Dag2SYyRBB6NjY3Rq1ev6hrpkXR48ODBX3peUpAVZSBL1DUga9Q1IGvUNSBr1DWgmnzZCI9dLGQOAAAAAABkgtADAAAAAADIhKoLPWpra+PGG29MbwGyQF0DskZdA7JGXQOyRl0DsqzbLWQOAAAAAADQI0Z6AAAAAAAA7I3QAwAAAAAAyAShBwAAAAAAkAlCDwAAAAAAIBOEHgAAAAAAQCZUXehx//33xxFHHBF9+/aNU089NVatWlXpLgF8qebm5hg9enTU1dXFIYccEpMmTYr169d3OOezzz6LadOmxcCBA+Ob3/xmXHjhhbFly5aK9Rlgf9xxxx2Ry+Vi+vTp7cfUNaDavPfee3HppZemdatfv34xYsSIWLNmTfv9xWIx5syZE4MGDUrvHz9+fLz11lsV7TPAF9m5c2fMnj07hg4dmtasYcOGxS233JLWsl3UNSCLqir0WLRoUcycOTNuvPHGWLduXYwcOTImTJgQW7durXTXAPbpxRdfTD/4W7FiRbzwwguxffv2OOecc2Lbtm3t58yYMSP++Mc/xu9///v0/E2bNsW3v/3tivYb4KtYvXp1PPjgg3H88cd3OK6uAdXkww8/jLFjx0afPn3iueeei7/97W/xq1/9KgYMGNB+zl133RX33HNPLFiwIFauXBn9+/dP35MmIS9Ad3PnnXfG/Pnz47777ou///3v6X5Sx+699972c9Q1IItyxd3j3W4uGdmRXCmdFOtEW1tbNDU1xdVXXx033HBDpbsH8JW9//776YiP5EPAM888M/L5fBx88MGxcOHC+M53vpOe849//COOOeaYWL58eYwZM6bSXQbYq08++SROPPHEeOCBB+LWW2+NUaNGxbx589Q1oOok7yn/+te/xl/+8pe93p+8dW5sbIyf/OQn8dOf/jQ9ltS6Qw89NB599NG45JJLurjHAPt2/vnnpzXq17/+dfuxZORtMqLjd7/7nboGZFbVjPT4/PPPY+3atekwu1169eqV7idvnAGqSfJCMnHggQemt0l9S0Z/7F7jjj766BgyZIgaB3RrySi28847r0P9SqhrQLV55pln4uSTT46LLroovTjlhBNOiIcffrj9/nfeeSc2b97coa41NDSkF+epa0B3dPrpp8fSpUtjw4YN6f7rr78eL7/8cpx77rnpvroGZFVNVIkPPvggnYswSZt3l+wnVw0CVItklFoy530yfcLw4cPTY8kLzQMOOCC+9a1v7VHjkvsAuqMnn3wynXI0md7q36lrQLV5++2302lgkimVf/7zn6e17Zprrklr2ZQpU9pr197ek6prQHcdwVYoFNILT3r37p1+rnbbbbfF5MmT0/vVNSCrqib0AMjSVdFvvvlmeoUNQLVqaWmJa6+9Nl2nqG/fvpXuDkBJLkxJRnrcfvvt6X4y0iN5zZbMc5+EHgDV5qmnnorHH388nW70uOOOi9deey29AC+Z0kpdA7Ksaqa3Ouigg9JUesuWLR2OJ/uHHXZYxfoFsD+uuuqqePbZZ+PPf/5zDB48uP14UseSafw++uijDuercUB3lUxftXXr1nQ9j5qamnRL1ilKFsJMvk6uEFTXgGoyaNCgOPbYYzscS9Yhevfdd9Ovd9Uu70mBanHdddeloz2StTlGjBgR3/ve92LGjBnR3Nyc3q+uAVlVNaFHMqT4pJNOSuci3P1KnGT/tNNOq2jfAL5MskBcEng8/fTT8ac//SmGDh3a4f6kvvXp06dDjVu/fn36JluNA7qjs88+O9544430isFdW3KFdDJdwq6v1TWgmiRTjyZ1anfJPPiHH354+nXy+i35EHD3upZMG7Ny5Up1DeiWPv3003Q93N0lFxQnn6cl1DUgq6pqeqtkbtVk+F3yJvqUU06JefPmxbZt22Lq1KmV7hrAl05plQwpXrx4cdTV1bXPj5osEtevX7/09gc/+EFa55LFzevr6+Pqq69OX2iOGTOm0t0H2ENSy3atS7RL//79Y+DAge3H1TWgmiRXPyeL/ibTW333u9+NVatWxUMPPZRuiVwul04Lc+utt8ZRRx2Vflg4e/bsdJqYSZMmVbr7AHu44IIL0jU8hgwZkk5v9eqrr8bdd98dl112WXq/ugZkVVWFHhdffHG8//77MWfOnPQDw1GjRsWSJUv2WHAJoLtJFsVMjBs3rsPxRx55JL7//e+nX8+dOze9CufCCy+M1tbWmDBhQjzwwAMV6S9AKahrQDUZPXp0Oip31qxZcfPNN6cf/iUX2u1a8Ddx/fXXpxfeXX755en0fWeccUb6ntTaRkB3dO+996YhxpVXXplOS5qEGVdccUX6udou6hqQRbliMucKAAAAAABAlauaNT0AAAAAAAD2RegBAAAAAABkgtADAAAAAADIBKEHAAAAAACQCUIPAAAAAAAgE4QeAAAAAABAJgg9AAAAAACATBB6AAAAAAAAmSD0AAAAAAAAMkHoAQAAAAAAZILQAwAAAAAAiCz4XzmGEdv/PpifAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 2000x1000 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize = (20,10))\n",
        "plt.imshow(100*chroma[:100,:].T)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YBxV2uQWYEB"
      },
      "source": [
        "##### Question 1 [5 points]\n",
        "Describe what the chromas function does. In your answer refer to musical terms of note names and octave numbers. How does that resemble or differ from the chroma feature that is computed for audio spectrum? Use the figures to demonstrate the explanation.\n",
        "\n",
        "Hint: Refresh the musical terms by looking at the lecture slides and consider what type of music anaylsis the audio chroma is used for. If you are interested more in musical theory you may also consider the concepts of \"pitch class\" and \"music set theory\" that are explained in https://en.wikipedia.org/wiki/Musical_note and https://en.wikipedia.org/wiki/Set_theory_%28music%29"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hhMa419WYEB"
      },
      "source": [
        "the add_chromas function takes in a dictionary of songs and adds a chroma feature to each song in the dictionary.\n",
        "for each song in the songs (which is the piano roll of the song), extract the chroma features by finding the notes that are played at each time step \n",
        "by checking if the value of each of the 78 piano roll notes is greater than 0 - active. if so we find the musical (c,d,e,f...) note using mod 12 and increment the corresponding index in the chroma feature - chord."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIhhTSj6GtvT"
      },
      "source": [
        "# 2. Setting Up GAN Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIaKKrWmEj1w",
        "outputId": "5bd4c581-204f-4706-a2a6-c9edfde2e467"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "624 48\n"
          ]
        }
      ],
      "source": [
        "lowest_note = 0 #the index of the lowest note on the piano roll\n",
        "highest_note = 78 #the index of the highest note on the piano roll\n",
        "note_range = highest_note-lowest_note #the note range\n",
        "\n",
        "num_timesteps  = 4 #This is the number of timesteps that we will create at a time\n",
        "X_dim = 2*note_range*num_timesteps #This is the size of the visible layer.\n",
        "Z_dim = 12*num_timesteps \n",
        "n_hidden = 50 #This is the size of the hidden layer\n",
        "\n",
        "print(X_dim,Z_dim)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byxUD8BDWYEC"
      },
      "source": [
        "##### Question 2 [5 points]\n",
        "\n",
        "Explain what aspects of music (pitch, rhythm, note duration) are captured by the latent random Z? In your answer refer to the representaiton of the song data. Note how song matrix differs from standard pianoroll."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XGBCf4JWYEC"
      },
      "source": [
        "The latent random Z captures the harmony structure over multiple timesteps of the music by encoding chroma features (pitch classes like C, D, E, etc.) over time. Rhythm and note duration are not explicitly included, they are indirectly represented through changes in chroma activity over time. Unlike the detailed piano roll, which includes velocity and note-on/off data for 78 keys, Z provides a high-level abstraction of the song, emphasizing tonal and harmonic patterns.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "uDpINNjpEj1x"
      },
      "outputs": [],
      "source": [
        "def xavier_init(size):\n",
        "    in_dim = size[0]\n",
        "    xavier_stddev = 1. / tf.sqrt(in_dim / 2.)\n",
        "    return tf.random_normal(shape=size, stddev=xavier_stddev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "24NXtz5IEj1x"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /Users/roybh/.pyenv/versions/audio_exc4/lib/python3.12/site-packages/tensorflow/python/compat/v2_compat.py:98: disable_resource_variables (from tensorflow.python.ops.resource_variables_toggle) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ],
      "source": [
        "tf.disable_v2_behavior()\n",
        "\n",
        "#setting up model, discriminator weights and biases\n",
        "X = tf.placeholder(tf.float32, shape=[None, X_dim])\n",
        "\n",
        "\n",
        "D_W1 = tf.Variable(xavier_init([X_dim+Z_dim, 512]))\n",
        "D_b1 = tf.Variable(tf.zeros(shape=[512]))\n",
        "\n",
        "D_W2 = tf.Variable(xavier_init([512, 1]))\n",
        "D_b2 = tf.Variable(tf.zeros(shape=[1]))\n",
        "\n",
        "theta_D = [D_W1, D_W2, D_b1, D_b2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "LRLHyW-CEj1x"
      },
      "outputs": [],
      "source": [
        "#setting up model, generator weights and biases\n",
        "\n",
        "#z is the space we're generating from\n",
        "Z = tf.placeholder(tf.float32, shape=[None, Z_dim])\n",
        "\n",
        "G_W1 = tf.Variable(xavier_init([Z_dim, 128]))\n",
        "G_b1 = tf.Variable(tf.zeros(shape=[128]))\n",
        "\n",
        "G_W2 = tf.Variable(xavier_init([128, X_dim]))\n",
        "G_b2 = tf.Variable(tf.zeros(shape=[X_dim]))\n",
        "\n",
        "theta_G = [G_W1, G_W2, G_b1, G_b2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "mIjKz4MwEj1x"
      },
      "outputs": [],
      "source": [
        "def generator(z):\n",
        "    G_h1 = tf.nn.relu(tf.matmul(z, G_W1) + G_b1)\n",
        "    G_log_prob = tf.matmul(G_h1, G_W2) + G_b2\n",
        "    G_prob = tf.nn.sigmoid(G_log_prob)\n",
        "\n",
        "    return G_prob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "bWImNLv-Ej1y"
      },
      "outputs": [],
      "source": [
        "def discriminator(x,c):\n",
        "\n",
        "    D_h1 = tf.nn.relu(tf.matmul(tf.concat([x,c],1), D_W1) + D_b1)\n",
        "    D_logit = tf.matmul(D_h1, D_W2) + D_b2\n",
        "    D_prob = tf.nn.sigmoid(D_logit)\n",
        "\n",
        "    return D_prob, D_logit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "tI8yFjDWEj1y"
      },
      "outputs": [],
      "source": [
        "def plot(samples):\n",
        "    fig = plt.figure(figsize=(4, 4))\n",
        "    gs = gridspec.GridSpec(4, 4)\n",
        "    gs.update(wspace=0.05, hspace=0.05)\n",
        "\n",
        "    for i, sample in enumerate(samples):\n",
        "        ax = plt.subplot(gs[i])\n",
        "        plt.axis('off')\n",
        "        ax.set_xticklabels([])\n",
        "        ax.set_yticklabels([])\n",
        "        ax.set_aspect('equal')\n",
        "\n",
        "        plt.imshow(sample.reshape(78, 30), cmap='Greys_r')\n",
        "\n",
        "\n",
        "    return fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "P8CrxuCaEj1z"
      },
      "outputs": [],
      "source": [
        "G_sample = generator(Z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "kjJ7f5I-Ej10"
      },
      "outputs": [],
      "source": [
        "D_real, D_logit_real = discriminator(X,Z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "n8992jJOEj10"
      },
      "outputs": [],
      "source": [
        "D_fake, D_logit_fake = discriminator(G_sample,Z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dh8fl0XfWYEF"
      },
      "source": [
        "##### Question 3 [10 points]\n",
        "In standard GAN, the discriminator receives as input true or fake (generated) data only. Explain why in our case the disrciminator receives as input both the data and an additional variable Z? How this Z differs from the usual GAN input of a random vector?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7IG3GowWYEF"
      },
      "source": [
        "This is different from a standard GAN discriminator because it's conditional - it doesn't just try to determine if the input is real or fake, but also checks if it matches the given chroma features. This helps ensure the generated music maintains the harmonic structure specified by the chroma input.\n",
        "The discriminator is essentially learning to identify not just realistic music, but realistic music that properly corresponds to the given chroma features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "tcYoVloPEj10"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Alternative losses:\n",
        "# -------------------\n",
        "Lambda = 100\n",
        "D_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_real, labels=tf.ones_like(D_logit_real)))\n",
        "D_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_fake, labels=tf.zeros_like(D_logit_fake)))\n",
        "D_loss = D_loss_real + D_loss_fake\n",
        "G_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_fake, labels=tf.ones_like(D_logit_fake)))\n",
        "G_loss_L1 = tf.reduce_mean(tf.losses.mean_squared_error(X,G_sample))\n",
        "G_loss = G_loss_fake + Lambda*G_loss_L1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXhwRKjdWYEF"
      },
      "source": [
        "##### Question 4 [10 points]\n",
        "Explain the two components of the discriminator loss in the D_loss expression. Why the real loss uses tf.ones_like andthe fake loss uses tf.zeros_like in the cross entory loss? What are the statistical distributions (which datasets are used) in computational of the real and fake losses. In your answers you may either include an equation image or write the loss equaiton in latex mathamtical notation inside Markdown cell."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHQeph5cWYEF"
      },
      "source": [
        "### Discriminator Loss Components\n",
        "\n",
        "D_loss_real - its the real data componenet and we use one_like because we want to maximize the probability of correctly identifying real samples (output close to 1)\n",
        "D_loss_fake - This component handles generated/fake samples. and we use zero_like because we want to minimize the probability of being fooled by generated samples (output close to 0) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiUKc6qaWYEG"
      },
      "source": [
        "##### Question 5 [10 points]\n",
        "In the generator loss G_loss we add an L1 loss. What does it represent? Why do you think we might want to add the L1 loss to the GAN model? We will explore this question further down the assignment, so at this point write down your best explanation based on the equations themselves without running any experiments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGnjeFAZWYEG"
      },
      "source": [
        "The G loss includes an L1 loss term, which measures the mean squared error between the real data X and the generated data G sample. This ensures that the generator not only fools the discriminator but also produces outputs that closely resemble the real data in terms of structure and content. Adding the L1 loss helps \"guide\" the generator toward generating samples that are realistic and aligned with the true data distribution, rather than just optimizing to fool the discriminator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Oc9zTKiEEj11"
      },
      "outputs": [],
      "source": [
        "#optimizing functions\n",
        "D_solver = tf.train.AdamOptimizer().minimize(D_loss, var_list=theta_D)\n",
        "G_solver = tf.train.AdamOptimizer().minimize(G_loss, var_list=theta_G)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "V_yjcm__Ej11"
      },
      "outputs": [],
      "source": [
        "#output midi file folder\n",
        "if not os.path.exists('out/'):\n",
        "    os.makedirs('out/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "wMfONb8gEj11"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1737538737.061637 111630365 mlir_graph_optimization_pass.cc:401] MLIR V1 optimization pass is not enabled\n"
          ]
        }
      ],
      "source": [
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AI2HBr6YGzkM"
      },
      "source": [
        "# 3. Training GAN Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "FZBAHllDEj11",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iter: 0\n",
            "D_Loss: 1.22\n",
            "G_Loss: 32.27\n",
            "Iter: 1000\n",
            "D_Loss: 0.1158\n",
            "G_Loss: 5.528\n",
            "Iter: 2000\n",
            "D_Loss: 0.02594\n",
            "G_Loss: 7.597\n",
            "Iter: 3000\n",
            "D_Loss: 0.0003483\n",
            "G_Loss: 18.34\n",
            "Iter: 4000\n",
            "D_Loss: 0.000237\n",
            "G_Loss: 18.82\n",
            "Iter: 5000\n",
            "D_Loss: 0.2393\n",
            "G_Loss: 9.069\n",
            "Iter: 6000\n",
            "D_Loss: 0.0004441\n",
            "G_Loss: 19.33\n",
            "Iter: 7000\n",
            "D_Loss: 7.651e-05\n",
            "G_Loss: 17.02\n",
            "Iter: 8000\n",
            "D_Loss: 0.00119\n",
            "G_Loss: 12.14\n",
            "Iter: 9000\n",
            "D_Loss: 0.0002839\n",
            "G_Loss: 20.39\n",
            "Iter: 10000\n",
            "D_Loss: 3.257e-05\n",
            "G_Loss: 23.22\n",
            "Iter: 11000\n",
            "D_Loss: 9.201e-06\n",
            "G_Loss: 19.77\n",
            "Iter: 12000\n",
            "D_Loss: 1.698e-05\n",
            "G_Loss: 29.59\n",
            "Iter: 13000\n",
            "D_Loss: 1.526e-05\n",
            "G_Loss: 23.87\n",
            "Iter: 14000\n",
            "D_Loss: 2.003e-06\n",
            "G_Loss: 25.09\n",
            "Iter: 15000\n",
            "D_Loss: 1.265e-06\n",
            "G_Loss: 24.96\n",
            "Iter: 16000\n",
            "D_Loss: 0.0006578\n",
            "G_Loss: 22.96\n",
            "Iter: 17000\n",
            "D_Loss: 4.536e-08\n",
            "G_Loss: 27.56\n",
            "Iter: 18000\n",
            "D_Loss: 6.117e-08\n",
            "G_Loss: 30.48\n",
            "Iter: 19000\n",
            "D_Loss: 2.813e-08\n",
            "G_Loss: 32.1\n",
            "Iter: 20000\n",
            "D_Loss: 1.388e-07\n",
            "G_Loss: 33.47\n",
            "Iter: 21000\n",
            "D_Loss: 6.465e-10\n",
            "G_Loss: 32.86\n",
            "Iter: 22000\n",
            "D_Loss: 5.45e-09\n",
            "G_Loss: 40.08\n",
            "Iter: 23000\n",
            "D_Loss: 1.489e-08\n",
            "G_Loss: 46.17\n",
            "Iter: 24000\n",
            "D_Loss: 7.027e-09\n",
            "G_Loss: 54.6\n",
            "Iter: 25000\n",
            "D_Loss: 5.273e-09\n",
            "G_Loss: 29.27\n",
            "Iter: 26000\n",
            "D_Loss: 2.637e-08\n",
            "G_Loss: 22.65\n",
            "Iter: 27000\n",
            "D_Loss: 1.006e-07\n",
            "G_Loss: 27.79\n",
            "Iter: 28000\n",
            "D_Loss: 4.199e-12\n",
            "G_Loss: 36.09\n",
            "Iter: 29000\n",
            "D_Loss: 7.621e-10\n",
            "G_Loss: 30.92\n",
            "Iter: 30000\n",
            "D_Loss: 6.533e-11\n",
            "G_Loss: 33.91\n",
            "Iter: 31000\n",
            "D_Loss: 4.501e-11\n",
            "G_Loss: 32.48\n",
            "Iter: 32000\n",
            "D_Loss: 4.209e-10\n",
            "G_Loss: 35.03\n",
            "Iter: 33000\n",
            "D_Loss: 9.977e-09\n",
            "G_Loss: 33.66\n",
            "Iter: 34000\n",
            "D_Loss: 2.266e-11\n",
            "G_Loss: 38.59\n",
            "Iter: 35000\n",
            "D_Loss: 9.808e-10\n",
            "G_Loss: 50.41\n",
            "Iter: 36000\n",
            "D_Loss: 2.34e-11\n",
            "G_Loss: 35.18\n",
            "Iter: 37000\n",
            "D_Loss: 4.123e-10\n",
            "G_Loss: 31.61\n",
            "Iter: 38000\n",
            "D_Loss: 3.905e-12\n",
            "G_Loss: 34.19\n",
            "Iter: 39000\n",
            "D_Loss: 1.466e-09\n",
            "G_Loss: 28.87\n",
            "Iter: 40000\n",
            "D_Loss: 4.027e-11\n",
            "G_Loss: 32.73\n",
            "Iter: 41000\n",
            "D_Loss: 3.543e-11\n",
            "G_Loss: 33.52\n",
            "Iter: 42000\n",
            "D_Loss: 1.004e-09\n",
            "G_Loss: 30.22\n",
            "Iter: 43000\n",
            "D_Loss: 2.336e-09\n",
            "G_Loss: 33.44\n",
            "Iter: 44000\n",
            "D_Loss: 7.094e-11\n",
            "G_Loss: 45.19\n",
            "Iter: 45000\n",
            "D_Loss: 1.599e-15\n",
            "G_Loss: 53.52\n",
            "Iter: 46000\n",
            "D_Loss: 8.017e-12\n",
            "G_Loss: 42.39\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[25], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m ch \u001b[38;5;241m=\u001b[39m chroma[ind:ind\u001b[38;5;241m+\u001b[39mbatch_size]\n\u001b[1;32m     25\u001b[0m _, D_loss_curr \u001b[38;5;241m=\u001b[39m sess\u001b[38;5;241m.\u001b[39mrun([D_solver, D_loss], feed_dict\u001b[38;5;241m=\u001b[39m{X: X_mb, Z: ch})\n\u001b[0;32m---> 26\u001b[0m _, G_loss_curr \u001b[38;5;241m=\u001b[39m \u001b[43msess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mG_solver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mG_loss\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mX\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mZ\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mch\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m1000\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIter: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(i))\n",
            "File \u001b[0;32m~/.pyenv/versions/audio_exc4/lib/python3.12/site-packages/tensorflow/python/client/session.py:977\u001b[0m, in \u001b[0;36mBaseSession.run\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    974\u001b[0m run_metadata_ptr \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_NewBuffer() \u001b[38;5;28;01mif\u001b[39;00m run_metadata \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 977\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mrun_metadata_ptr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    979\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m run_metadata:\n\u001b[1;32m    980\u001b[0m     proto_data \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
            "File \u001b[0;32m~/.pyenv/versions/audio_exc4/lib/python3.12/site-packages/tensorflow/python/client/session.py:1220\u001b[0m, in \u001b[0;36mBaseSession._run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1217\u001b[0m \u001b[38;5;66;03m# We only want to really perform the run if fetches or targets are provided,\u001b[39;00m\n\u001b[1;32m   1218\u001b[0m \u001b[38;5;66;03m# or if the call is a partial run that specifies feeds.\u001b[39;00m\n\u001b[1;32m   1219\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m final_fetches \u001b[38;5;129;01mor\u001b[39;00m final_targets \u001b[38;5;129;01mor\u001b[39;00m (handle \u001b[38;5;129;01mand\u001b[39;00m feed_dict_tensor):\n\u001b[0;32m-> 1220\u001b[0m   results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_targets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_fetches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mfeed_dict_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1223\u001b[0m   results \u001b[38;5;241m=\u001b[39m []\n",
            "File \u001b[0;32m~/.pyenv/versions/audio_exc4/lib/python3.12/site-packages/tensorflow/python/client/session.py:1400\u001b[0m, in \u001b[0;36mBaseSession._do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1397\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_tf_sessionprun(handle, feed_dict, fetch_list)\n\u001b[1;32m   1399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1400\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_run_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeeds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1401\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1402\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1403\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_call(_prun_fn, handle, feeds, fetches)\n",
            "File \u001b[0;32m~/.pyenv/versions/audio_exc4/lib/python3.12/site-packages/tensorflow/python/client/session.py:1407\u001b[0m, in \u001b[0;36mBaseSession._do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_do_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m   1406\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1407\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1408\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOpError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1409\u001b[0m     message \u001b[38;5;241m=\u001b[39m compat\u001b[38;5;241m.\u001b[39mas_text(e\u001b[38;5;241m.\u001b[39mmessage)\n",
            "File \u001b[0;32m~/.pyenv/versions/audio_exc4/lib/python3.12/site-packages/tensorflow/python/client/session.py:1390\u001b[0m, in \u001b[0;36mBaseSession._do_run.<locals>._run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1387\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_fn\u001b[39m(feed_dict, fetch_list, target_list, options, run_metadata):\n\u001b[1;32m   1388\u001b[0m   \u001b[38;5;66;03m# Ensure any changes to the graph are reflected in the runtime.\u001b[39;00m\n\u001b[1;32m   1389\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extend_graph()\n\u001b[0;32m-> 1390\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_tf_sessionrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetch_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1391\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mtarget_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.pyenv/versions/audio_exc4/lib/python3.12/site-packages/tensorflow/python/client/session.py:1483\u001b[0m, in \u001b[0;36mBaseSession._call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1481\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_call_tf_sessionrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, options, feed_dict, fetch_list, target_list,\n\u001b[1;32m   1482\u001b[0m                         run_metadata):\n\u001b[0;32m-> 1483\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_SessionRun_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1484\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mfetch_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1485\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "i = 0\n",
        "num_epochs = 200000\n",
        "batch_size = 100\n",
        "S_cutoff = 0.5\n",
        "#commented out print statements output different losses, and plotting functions plot the piano roll and chroma.\n",
        "while i <= num_epochs:\n",
        "    # for song, chroma in zip(songs, chromas):\n",
        "    for files in songs:\n",
        "        song = songs[files]['song']\n",
        "        chroma = songs[files]['chroma']\n",
        "        # The songs are stored in a time x notes format. The size of each song is timesteps_in_song x 2*note_range\n",
        "        # Here we reshape the songs so that each training example is a vector with num_timesteps x 2*note_range elements\n",
        "        song = np.array(song)\n",
        "        song_steps = np.floor(song.shape[0]/num_timesteps).astype(int)\n",
        "        song = song[:song_steps*num_timesteps]\n",
        "        song = np.reshape(song, [song_steps, song.shape[1]*num_timesteps])\n",
        "        chroma = np.array(chroma)\n",
        "        chroma = chroma[:song_steps*num_timesteps]\n",
        "        chroma = np.reshape(chroma, [song_steps, chroma.shape[1]*num_timesteps])\n",
        "        batch_size = min(batch_size,len(song))\n",
        "        # Train the RBM on batch_size examples at a time\n",
        "        for ind in range(0, len(song), batch_size):\n",
        "            X_mb = song[ind:ind+batch_size]\n",
        "            ch = chroma[ind:ind+batch_size]\n",
        "            _, D_loss_curr = sess.run([D_solver, D_loss], feed_dict={X: X_mb, Z: ch})\n",
        "            _, G_loss_curr = sess.run([G_solver, G_loss], feed_dict={X: X_mb, Z: ch})\n",
        "\n",
        "            if i % 1000 == 0:\n",
        "                print('Iter: {}'.format(i))\n",
        "                dloss = ('D_Loss: {:.4}'. format(D_loss_curr))\n",
        "                gloss = ('G_Loss: {:.4}'. format(G_loss_curr))\n",
        "                print(dloss)\n",
        "                print(gloss)\n",
        "\n",
        "                samples = sess.run(G_sample, feed_dict={Z: ch})\n",
        "\n",
        "                S = np.reshape(samples, (ch.shape[0]*num_timesteps, 2*note_range))\n",
        "                thresh_S = S>=S_cutoff\n",
        "\n",
        "                thresh_S = np.transpose(thresh_S)\n",
        "\n",
        "\n",
        "                C = np.reshape(ch, (ch.shape[0]*num_timesteps, 12))\n",
        "\n",
        "                test = reverse_pianoroll.piano_roll_to_pretty_midi(convert.back(thresh_S), fs=16)\n",
        "                test.write('out/{}.mid'.format(i))\n",
        "\n",
        "            i += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9svDngpHzty"
      },
      "source": [
        "# 4. Style Transfer with a New Genre Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O12p-OvfWYEI"
      },
      "source": [
        "In this part we will explore using the trained GAN to compose new music according to the harmonic structure of another musical input. In a way this comprises of a style transfer between the input music that belongs to style A and the output music that is generated using GAN trained on style B. In the example we will used J.S.Bach as our input (Style A) and output music in Mozart's style that was use to train our GAN (Style B). The new Mozart piece should follow the harmonic structure (chord progressions) of the Bach input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "SSzNXQleEj13",
        "outputId": "6d117973-ae1e-4be4-c2d7-77aba8ea94d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3 songs processed\n",
            "3 chromas processed\n"
          ]
        }
      ],
      "source": [
        "#for testing, we will be using a different composer dataset to input into the generator here.\n",
        "test_song = get_songs(\"./content/Classical_Music_Midi/bach\")\n",
        "test_song = add_chromas(test_song)\n",
        "\n",
        "print (\"{} songs processed\".format(len(['song' in test_song[f] for f in test_song])))\n",
        "print (\"{} chromas processed\".format(len(['chroma' in test_song[f] for f in test_song])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "g-lb4wigiXTm"
      },
      "outputs": [],
      "source": [
        "#converted midi file folder\n",
        "if not os.path.exists('converted/'):\n",
        "    os.makedirs('converted/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "R1yURaYKEj14"
      },
      "outputs": [],
      "source": [
        "i = 0\n",
        "S_cutoff = 0.5\n",
        "\n",
        "# for i,c in enumerate(test_chromaz):\n",
        "for song in test_song:\n",
        "    test_chroma = np.array(test_song[song]['chroma'])\n",
        "\n",
        "    test_chroma = test_chroma[:np.floor(test_chroma.shape[0]/num_timesteps).astype(int)*num_timesteps]\n",
        "    test_chroma = np.reshape(test_chroma, [int(test_chroma.shape[0]/num_timesteps), test_chroma.shape[1]*num_timesteps])\n",
        "\n",
        "    out_samples = sess.run(G_sample, feed_dict={Z: test_chroma})\n",
        "\n",
        "    S = np.reshape(out_samples, (np.floor(out_samples.shape[0]*out_samples.shape[1]/2/note_range).astype(int), 2*note_range))\n",
        "    C = np.reshape(test_chroma, (test_chroma.shape[0]*num_timesteps, 12))\n",
        "\n",
        "    thresh_S = S>=S_cutoff\n",
        "    thresh_S = np.transpose(thresh_S)\n",
        "\n",
        "    test = reverse_pianoroll.piano_roll_to_pretty_midi(convert.back(thresh_S), fs=16)\n",
        "    test_song[song]['generated'] = test\n",
        "    test.write('converted/{}.mid'.format(song.split('/')[-1].split('.')[0]+\"generated\"))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mecEOik9WYEI"
      },
      "source": [
        "##### Question 6 [10 points]\n",
        "Open the conversion results in a musical MIDI software (such as Musescore) and observe/listen to the results. Write down your impressions about the quality of the musical texture style transfer - did the harmonic structure follow the Bach input? How did the notes distribution (choice of pitches and durations) change relative to the original Bach piece? Does the S_cutoff parameter affect the outcome, and if so, how?\n",
        "\n",
        "Summarize your findings and suggest some conclusions. Can you point to any musical aspects that were poorly modeled and ideas of improvement?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emLJzZ0JWYEJ"
      },
      "source": [
        "``` your response here ```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfiNHssBWYEJ"
      },
      "source": [
        "# 5. Further experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9N-BA73WYEJ"
      },
      "source": [
        "##### Question 7 & 8: [total 30 points]\n",
        "\n",
        "Choose two of the experiments and report their results:\n",
        "\n",
        "1. Explore style transfer between more distant styles: For this purpose you may use the Pop_Music_Midi dataset and repeat the Style Transfer Experiment between Classical and Pop music (and vice versa). Report your findings in qualitative ways and submit the midi results together with your explanation. [20 Points]\n",
        "\n",
        "2. Expermment with L1 distance: retrain the GAN model with very small and very large Lambda. What are the effects of such changes? When is the texture of the output more or less musical? Are the harmonic progressions of the input followed or ignored? Any other observations? [20 Points]\n",
        "\n",
        "3. Create your own song: use the leadsheet2chroma.py file provided to create a Mozart style composition from your own leadsheet input. Provide the leadsheet in text format and the midi file results. Report your observations about the musical quality of the results. You may alter the leadsheet2chroma.py to fit other chords if you wish, or train GAN in a style different then Mozart. [20 Points]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHmu1PDiIP97"
      },
      "source": [
        "``` your response here ```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLxi0zt_HoZF"
      },
      "source": [
        "##### Question 9 [20 points]\n",
        "\n",
        "Please record a 2-5 minute video of yourself explaining questions 1 to 7.\n",
        "\n",
        "If you are shy (or have a bad hairday) you can use filters to augment or cover your face. Please submit it as a public google drive url."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjrtXvLyIUxo"
      },
      "source": [
        "``` your response here ```"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "audio_exc4",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
